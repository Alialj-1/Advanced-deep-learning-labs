{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loading_code as loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\n",
    "\n",
    "def preprocess_pandas(data, columns):\n",
    "    df_ = pd.DataFrame(columns=columns)\n",
    "    data['Sentence'] = data['Sentence'].str.lower()\n",
    "    data['Sentence'] = data['Sentence'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n",
    "    data['Sentence'] = data['Sentence'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n",
    "    data['Sentence'] = data['Sentence'].str.replace('[^\\w\\s]','')                                                       # remove special characters\n",
    "    data['Sentence'] = data['Sentence'].replace('\\d', '', regex=True)                                                   # remove numbers\n",
    "    for index, row in data.iterrows():\n",
    "        word_tokens = word_tokenize(row['Sentence'])\n",
    "        filtered_sent = [w for w in word_tokens if not w in stopwords.words('english')]\n",
    "        new_row = pd.DataFrame([{\n",
    "            \"index\": row['index'],\n",
    "            \"Class\": row['Class'],\n",
    "            \"Sentence\": \" \".join(filtered_sent)\n",
    "        }])\n",
    "        df_ = pd.concat([df_, new_row], ignore_index=True)\n",
    "    return data\n",
    "\n",
    "# If this is the primary file that is executed (ie not an import of another file)\n",
    "\n",
    "# get data, pre-process and split\n",
    "data = pd.read_csv(\"amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
    "data.columns = ['Sentence', 'Class']\n",
    "data['index'] = data.index                                          # add new column index\n",
    "columns = ['index', 'Class', 'Sentence']\n",
    "data = preprocess_pandas(data, columns)                             # pre-process\n",
    "training_data, validation_data, training_labels, validation_labels = train_test_split( # split the data into training, validation, and test splits\n",
    "    data['Sentence'].values.astype('U'),\n",
    "    data['Class'].values.astype('int32'),\n",
    "    test_size=0.10,\n",
    "    random_state=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# vectorize data using TFIDF and transform for PyTorch for scalability\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), max_features=50000, max_df=0.5, use_idf=True, norm='l2')\n",
    "training_data = word_vectorizer.fit_transform(training_data)        # transform texts to sparse matrix\n",
    "training_data = training_data.todense()                             # convert to dense matrix for Pytorch\n",
    "vocab_size = len(word_vectorizer.vocabulary_)\n",
    "validation_data = word_vectorizer.transform(validation_data)\n",
    "validation_data = validation_data.todense()\n",
    "train_x_tensor = torch.from_numpy(np.array(training_data)).type(torch.FloatTensor)\n",
    "train_y_tensor = torch.from_numpy(np.array(training_labels)).long()\n",
    "validation_x_tensor = torch.from_numpy(np.array(validation_data)).type(torch.FloatTensor)\n",
    "validation_y_tensor = torch.from_numpy(np.array(validation_labels)).long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, a very simple text classifier is created.\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.6911979556083679, Validation Loss: 0.6835850775241852, Accuracy: 0.47\n",
      "Epoch 2/10, Training Loss: 0.6496347268422444, Validation Loss: 0.6446263492107391, Accuracy: 0.81\n",
      "Epoch 3/10, Training Loss: 0.5676612734794617, Validation Loss: 0.5835311114788055, Accuracy: 0.84\n",
      "Epoch 4/10, Training Loss: 0.4428472578525543, Validation Loss: 0.5153145492076874, Accuracy: 0.85\n",
      "Epoch 5/10, Training Loss: 0.31120123465855914, Validation Loss: 0.45443807542324066, Accuracy: 0.85\n",
      "Epoch 6/10, Training Loss: 0.20794046719868978, Validation Loss: 0.40954481065273285, Accuracy: 0.85\n",
      "Epoch 7/10, Training Loss: 0.13493663867314656, Validation Loss: 0.38315702974796295, Accuracy: 0.84\n",
      "Epoch 8/10, Training Loss: 0.08983398750424385, Validation Loss: 0.3627917468547821, Accuracy: 0.86\n",
      "Epoch 9/10, Training Loss: 0.06355140333374341, Validation Loss: 0.3502170890569687, Accuracy: 0.86\n",
      "Epoch 10/10, Training Loss: 0.04759390217562517, Validation Loss: 0.34327663481235504, Accuracy: 0.85\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, validation_loader, num_epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  \n",
    "        running_loss = 0.0\n",
    "        for texts, labels in train_loader:\n",
    "            optimizer.zero_grad()   \n",
    "            outputs = model(texts)  \n",
    "            loss = criterion(outputs, labels)  \n",
    "            loss.backward()         \n",
    "            optimizer.step()        \n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()  \n",
    "        validation_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for texts, labels in validation_loader:\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validation_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_predictions += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader)}, Validation Loss: {validation_loss/len(validation_loader)}, Accuracy: {correct_predictions/total_predictions:.2f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "input_dim = vocab_size  # From how many input dimensions we have\n",
    "hidden_dim = 100        # 100 hidden neurons\n",
    "output_dim = 2          # Binary classification. Either positive or negative response\n",
    "\n",
    "model = TextClassifier(input_dim, hidden_dim, output_dim)\n",
    "#Cross entropy loss for classification problem\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Learning rate of 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = TensorDataset(validation_x_tensor, validation_y_tensor)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#Train model\n",
    "train_model(model, train_loader, validation_loader, num_epochs=10)\n",
    "\n",
    "#Save model\n",
    "torch.save(model.state_dict(), 'text_classifier_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'quit' to exit the program.\n",
      "User: heya\n",
      "Bot: Negative response.\n",
      "User: I think the product did not produce the expected outcome \n",
      "Bot: Negative response.\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "def prepare_input(text, word_vectorizer):\n",
    "    vectorized_text = word_vectorizer.transform([text]).todense()  # Vectorize the text\n",
    "    input_tensor = torch.from_numpy(np.array(vectorized_text)).type(torch.FloatTensor)\n",
    "    return input_tensor\n",
    "\n",
    "def generate_response(class_id):\n",
    "    responses = {\n",
    "        0: \"Negative response.\",\n",
    "        1: \"Positive response.\"\n",
    "    }\n",
    "    return responses.get(class_id, \"Unknown class response.\")\n",
    "\n",
    "def predict_and_respond(input_text, model, word_vectorizer):\n",
    "    input_tensor = prepare_input(input_text, word_vectorizer)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "        return generate_response(predicted_class.item())\n",
    "\n",
    "def main_loop(model, word_vectorizer):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(\"Type 'quit' to exit the program.\")\n",
    "    while True:\n",
    "        input_text = input(\"You: \")\n",
    "        if input_text.lower() == 'quit':\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "        response = predict_and_respond(input_text, model, word_vectorizer)\n",
    "        print(f'User: {input_text}')\n",
    "        print(\"Bot:\", response)\n",
    "\n",
    "#Load previously trained model\n",
    "model.load_state_dict(torch.load('text_classifier_model.pth'))\n",
    "\n",
    "#Create a loop which takes inputs, and generates output\n",
    "main_loop(model, word_vectorizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
